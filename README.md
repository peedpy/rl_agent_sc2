# ü§ñ Agente Q-Learning para StarCraft II

Un agente de inteligencia artificial basado en Q-Learning para jugar StarCraft II, implementado usando PySC2.

## üìã Descripci√≥n

Este proyecto implementa un agente de aprendizaje por refuerzo que aprende a jugar StarCraft II usando el algoritmo Q-Learning. El agente est√° dise√±ado para la raza Terran y puede realizar acciones b√°sicas como:

- **Econom√≠a**: Construir SCVs, recolectar minerales y gas
- **Infraestructura**: Construir edificios (cuarteles, dep√≥sitos, etc.)
- **Producci√≥n militar**: Entrenar Marines y Marauders
- **Combate**: Atacar unidades enemigas con estrategias t√°cticas
- **Exploraci√≥n**: Explorar el mapa para encontrar recursos y enemigos

## üèóÔ∏è Arquitectura del Proyecto

```
rl_agent_sc2/
‚îú‚îÄ‚îÄ actions/                 # M√≥dulos de acciones del juego
‚îÇ   ‚îú‚îÄ‚îÄ set_actions.py      # Configuraci√≥n centralizada de acciones
‚îÇ   ‚îú‚îÄ‚îÄ build_scv.py        # Entrenamiento de trabajadores
‚îÇ   ‚îú‚îÄ‚îÄ harvest_minerals.py # Recolecci√≥n de minerales
‚îÇ   ‚îú‚îÄ‚îÄ train_marine.py     # Entrenamiento de Marines
‚îÇ   ‚îú‚îÄ‚îÄ attack_army.py      # L√≥gica de combate
‚îÇ   ‚îî‚îÄ‚îÄ ...                 # Otras acciones
‚îú‚îÄ‚îÄ algorithms/             # Algoritmos de aprendizaje
‚îÇ   ‚îú‚îÄ‚îÄ q_learning.py       # Implementaci√≥n Q-Learning
‚îÇ   ‚îî‚îÄ‚îÄ rewards.py          # Sistema de recompensas
‚îú‚îÄ‚îÄ libs/                   # Utilidades y helpers
‚îÇ   ‚îú‚îÄ‚îÄ functions.py        # Funciones auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ logging_config.py   # Configuraci√≥n de logging
‚îú‚îÄ‚îÄ agent_qlearning.py      # Agente principal Q-Learning
‚îú‚îÄ‚îÄ agent_random.py         # Agente de referencia aleatorio
‚îî‚îÄ‚îÄ main_qlearning_agent__vs__ia_agent.py  # Script principal
```

## üöÄ Instalaci√≥n

### Requisitos Previos

1. **StarCraft II**: Descarga e instala StarCraft II desde [Battle.net](https://download.battle.net/en-us/desktop)
2. **Python 3.7+**: Aseg√∫rate de tener Python instalado

### Configuraci√≥n del Entorno

> **Nota**: Las siguientes instrucciones est√°n destinadas para entornos Windows.

#### 1. Configurar Entorno Virtual

```bash
# Crear entorno virtual
py -m venv .venv

# Activar entorno virtual
.venv\Scripts\activate

# Actualizar pip
py -m pip install --upgrade pip
```

#### 2. Instalar Dependencias

```bash
# Instalar todas las dependencias
pip install -r requirements.txt
```

O instalar manualmente:

```bash
# Instalar versiones espec√≠ficas
py -m pip install "pysc2==3.0.0"
py -m pip install "protobuf==3.19.4"
py -m pip install "pandas==1.4.3"
py -m pip install "numpy==1.22.4"
py -m pip install "chardet==4.0.0"
```

## üéÆ Ejecuci√≥n

### Agente Q-Learning

```bash
python main_qlearning_agent__vs__ia_agent.py
```

### Agente Aleatorio (Referencia)

```bash
python main_random_agent__vs__ia_agent.py
```

## üìä Sistema de Logging

El proyecto incluye un sistema de logging estructurado que proporciona:

- **Logs en consola** con colores para mejor legibilidad
- **Logs en archivo** con rotaci√≥n autom√°tica
- **Diferentes niveles** de logging (DEBUG, INFO, WARNING, ERROR)
- **Formato estructurado** con timestamp, nivel, m√≥dulo y mensaje

### Configuraci√≥n de Logging

```python
from libs.logging_config import setup_logging

# Configurar logging para desarrollo
setup_logging(log_level=logging.DEBUG, log_to_file=True, log_to_console=True)

# Configurar logging para producci√≥n
setup_logging(log_level=logging.INFO, log_to_file=True, log_to_console=False)
```

### Ejemplo de Uso

```python
import logging
logger = logging.getLogger(__name__)

logger.debug("Informaci√≥n detallada para debugging")
logger.info("Informaci√≥n general del proceso")
logger.warning("Advertencia sobre una situaci√≥n")
logger.error("Error que requiere atenci√≥n")
```

## üß† Algoritmo Q-Learning

### Caracter√≠sticas

- **Exploraci√≥n vs Explotaci√≥n**: Epsilon-greedy con decay exponencial
- **Persistencia**: Guardado y carga de tablas Q en CSV
- **Recompensas adaptativas**: Sistema de recompensas basado en m√∫ltiples m√©tricas
- **Pol√≠ticas compuestas**: Combinaciones inteligentes de acciones

### Hiperpar√°metros

```python
EXPLORATION_MAX = 1.0      # Exploraci√≥n inicial
EXPLORATION_MIN = 0.1      # Exploraci√≥n m√≠nima
EXPLORATION_DECAY = 0.0009 # Tasa de decay de exploraci√≥n
LEARNING_RATE = 0.01       # Tasa de aprendizaje
REWARD_DECAY = 0.8         # Factor de descuento
```

## üéØ Acciones Implementadas

### Acciones de Econom√≠a
- `build_scv`: Entrenar trabajadores
- `harvest_minerals`: Recolectar minerales
- `harvest_gas`: Construir refiner√≠as y recolectar gas

### Acciones de Infraestructura
- `build_supply_depot`: Construir dep√≥sitos de suministro
- `build_barracks`: Construir cuarteles
- `build_command_center`: Construir centros de mando
- `build_tech_lab`: Construir laboratorios tecnol√≥gicos
- `build_bunker`: Construir b√∫nkeres

### Acciones Militares
- `train_marine`: Entrenar Marines
- `train_marauder`: Entrenar Marauders
- `attack_with_marine`: Atacar con Marines
- `defense_with_marine`: Defender con Marines
- `attack_with_marauder`: Atacar con Marauders

### Acciones Estrat√©gicas
- `explore_csv`: Explorar el mapa

## üìà Pol√≠ticas de Acciones

El agente utiliza 14 pol√≠ticas predefinidas que combinan acciones de manera estrat√©gica:

```python
"policy_0": ["do_nothing"]                    # Control
"policy_1": ["build_scv"]                     # Econom√≠a b√°sica
"policy_2": ["harvest_minerals"]              # Recolecci√≥n
"policy_3": ["harvest_gas"]                   # Gas
"policy_4": ["build_command_center", "harvest_minerals", "harvest_minerals"]  # Expansi√≥n
"policy_5": ["explore_csv"]                   # Exploraci√≥n
"policy_6": ["build_supply_depot"]            # Infraestructura
"policy_7": ["build_barracks"] + 5 * ["train_marine"]  # Producci√≥n militar
"policy_8": ["build_bunker"]                  # Defensa
"policy_9": ["build_tech_lab"] + 2 * ["train_marauder"]  # Tecnolog√≠a
"policy_10": 5 * ["attack_with_marine"]       # Ataque masivo
"policy_11": 5 * ["defense_with_marine"]      # Defensa masiva
"policy_12": 5 * ["attack_with_marine"] + 2 * ["attack_with_marauder"]  # Combinado
"policy_13": 3 * ["attack_with_marauder"]     # Ataque especializado
```

## üîß Configuraci√≥n del Juego

### Entorno PySC2

```python
sc2_env.SC2Env(
    map_name="Simple64",                    # Mapa de entrenamiento
    players=[
        sc2_env.Agent(sc2_env.Race.terran, 'Q-learning'),
        sc2_env.Bot(sc2_env.Race.terran, sc2_env.Difficulty.very_easy)
    ],
    agent_interface_format=features.AgentInterfaceFormat(
        action_space=actions.ActionSpace.RAW,  # Acceso directo a unidades
        use_raw_units=True,                    # Informaci√≥n detallada
        raw_resolution=64,                     # Resoluci√≥n del mapa
    ),
    step_mul=16,                              # Velocidad del juego
    disable_fog=False,                        # Niebla de guerra activa
)
```

## üìÅ Estructura de Datos

### Archivos de Entrenamiento

- `new_qlearning_stats_train.csv`: Estad√≠sticas de entrenamiento
- `new_qlearning_table_train.csv`: Tabla Q actual
- `new_qlearning_status_game_train.csv`: Estado del juego por episodio

### Logs

- `logs/sc2_agent_YYYY-MM-DD_HH-MM-SS.log`: Archivos de log con timestamp

## ü§ù Contribuci√≥n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## üë®‚Äçüíª Autor

**Tu Nombre** - [tu-email@ejemplo.com](mailto:tu-email@ejemplo.com)

## üôè Agradecimientos

- [PySC2](https://github.com/deepmind/pysc2) - API de Python para StarCraft II
- [DeepMind](https://deepmind.com/) - Desarrollo de PySC2
- [Blizzard Entertainment](https://www.blizzard.com/) - StarCraft II

## üìö Referencias

- [PySC2 Documentation](https://github.com/deepmind/pysc2)
- [StarCraft II Wiki](https://liquipedia.net/starcraft2/Main_Page)
- [Q-Learning Algorithm](https://en.wikipedia.org/wiki/Q-learning)
